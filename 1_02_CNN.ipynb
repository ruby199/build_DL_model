{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3nPmsqx6CtAZGjZ4AtXA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruby199/build_DL_model/blob/main/Day1_02_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN for Feature Extraction \n",
        "* image/video - \n",
        "e.g. pinterest(hashtag as labeling-supervise learning)\n",
        "e.g. Adobe DeepFont (to detect specific designed font)\n",
        "\n",
        "* paper review youtube channel:\n",
        "https://www.youtube.com/@user-ow3gm9zd1b/featured\n",
        "\n",
        "\n",
        "* CNN (mostly used in image classification)\n",
        "* Fully-connected layer (어디 위치에 쓰이느냐에 따라 이름이 달라진다)"
      ],
      "metadata": {
        "id": "wlo6XWvRSxtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terminology\n",
        "- **channel**: A channel is like a separate color or information in an image. In color images, there are different channels for red, green, and blue. Each channel holds specific color information.\n",
        "\n",
        "- **Filter**: A filter is like a special tool used to modify an image. It can do things like making an image blurry, enhancing edges, or finding specific patterns. The filter uses a set of numbers to determine how it changes the image. 이미지에서 필요한/주요한 특징값만 추출하고 필요없는 특징값은 버리는 역할. CNN에서 feature값을 보고 판단/예측할 수 있다. filter안의 값들 = weight 값. *filter의 개수는 많을수록 좋고, 깊이도 깊을수록 더 좋다.* 중심부에서 더 많은 feature를 받게 된다.\n",
        "\n",
        "- Stride: How far to go to the right/bottom to perform the next convolution (중앙값 뿐만 아니라 다른 곳에도 가중치를 두기 위해서, 즉 몇칸씩 이동할지)\n",
        "\n",
        "- **Feature map**: A feature map is like a map that highlights specific features in an image. It's created by applying filters to the image. Each feature map shows the presence or intensity of a particular feature, such as edges or textures.\n",
        "\n",
        "- **padding**: Padding is like adding extra space around an image. It helps to keep the image size consistent during certain operations. Padding can be done by adding extra pixels with specific values, like zeros, around the edges of the image.\n",
        "\n",
        "- zero padding (0으로 테두리):  It involves adding extra rows and columns of zeros around the edges of an image or feature map before applying convolutional operations. 중앙필터 방지, & 가중으로 필터를 씌워야할 필요가 있을 때 - 이미지의 작아짐 방지. "
      ],
      "metadata": {
        "id": "g_Oj1vxHS2iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN composed layers\n",
        "- Convolutional Layer\n",
        "- Fully Connected Layer\n",
        "- Pooling Layer (cleaning up 정리정돈) - Max Pooling, Average Pooling. 짧은 시간안에 목표까지 도달할 수 있다.\n",
        "\n"
      ],
      "metadata": {
        "id": "EQciuyvxS7KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification\n",
        "CNN: 영상 이미지 뿐만 아니라 모든 matrix data 가능, including text data\n",
        "test -> 의미를 가지고 있는 vector값으로 표현...\n",
        "\n",
        "\n",
        "### <추세>  \n",
        "~2019 회귀 MLP. 이미지 CNN -> MLP MIXER , 자연어/시계열 RNN  -> CNN-> CNN + RNN\n",
        "\n",
        "2021~\n",
        "image, video - transformer (자연어에서 사용하던 transformer가 영상쪽에서 사용되자 기존 CNN 모두 이겨버림! 최고 성능을 내는 것은 결국 transformer이다)\n",
        "BUT transformer (CNN보다 훨씬 더 많은 cost) - 1%~2% +성능이기 때문에 실무에서는 더 작은 model인 CNN 선호.\n",
        "\n",
        "-> CNN + transformer (기반 model - 엄청난 성능, 그러나 엄청나게 크다) - 더 큰 transformer 모델이 무조건 성능이 좋기 때문에 성능적 개선을 연구하는 움직임은 침체. - 이제는 data적인 부분 (labeled/unlabeled data) 등 실무적인 부분에 대한 연구로 전향되고 있다. "
      ],
      "metadata": {
        "id": "ECJoqpRZS-wU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST dataset\n",
        "- CNN사용 유무에 따른 연산량의 차이, 속도 차이 비교/연구\n",
        "\n",
        "- Difference in computational complexity and speed comparison/research depending on the use of CNN.\n",
        "\n",
        "- MNIST data: 다양한 case, data class의 정확성, data가 많고 다양하다. 실무에서 좋은 data 확보하는 것이 매우 중요하다!"
      ],
      "metadata": {
        "id": "Oxj301MoSjBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI-OcQNcSj8j",
        "outputId": "842aa157-1629-4fb4-92cf-185816b29dd3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "rE-RLKVzSnAj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "xkWnN71cTNdE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# X_train, X_test norm(0-1)"
      ],
      "metadata": {
        "id": "LjtKt9F4VMMS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### try training without CNN"
      ],
      "metadata": {
        "id": "mcRsr8V4WR_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "#  multidimensional feature maps are reshaped into a single vector,(Here, it converts the 2D image into a 1D vector of size 784(28*28))\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28) )) # input shape: data하나의 크기가 관건이다. \n",
        "model.add(tf.keras.layers.Dense(128, activation='relu')) \n",
        "# input is 1D vector of size 784, each units in Dense layer has a weight for each input feature, 784*128=100,352 weights, 128 bias terms,\n",
        "# Thus, 100,352+128=100,480 parameters\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2)) # 특정 feature들을 가리고 학습하는 것. to prevent overfitting. \n",
        "\n",
        "model.add(tf.keras.layers.Dense(10 , activation ='softmax')) # This layer is defined with 10 units and uses the softmax activation function.\n",
        "# input is 1D vector of size 128. Thus, 10*128 = 1,280 weights. & bias term of 10, \n",
        "# Thus, 1,280 + 10 = 1,290 parameters\n",
        "\n",
        "model.summary() \n",
        "# Total: 100,480 + 1,290 = 101,770 parameters in the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_UL-7jdWMGS",
        "outputId": "57506d25-0691-4938-d1d3-6a904eb79c06"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building loss function and optimizer\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Y2yw3NE2bs5m"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 5, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA121vTTWyBz",
        "outputId": "67db0ddc-6691-4bf8-d1e4-17a350284d64"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2936 - accuracy: 0.9139 - val_loss: 0.1359 - val_accuracy: 0.9579\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1446 - accuracy: 0.9571 - val_loss: 0.0984 - val_accuracy: 0.9701\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1075 - accuracy: 0.9680 - val_loss: 0.0860 - val_accuracy: 0.9737\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9732 - val_loss: 0.0822 - val_accuracy: 0.9754\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0764 - accuracy: 0.9753 - val_loss: 0.0804 - val_accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e5853b4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- activation function: **linear to non-linear & normalization**\n",
        "- 층이 깊어질수록 모델 학습이 안된다 - 해결 with activation function.\n",
        "값의 범위를 줄이고, non-linear로 만드는 것. \n",
        "\n",
        "- hidden layer. output layer - 각각 어떤 function을 사용하는 것이 좋을까?\n",
        "\n",
        "- [정리] hidden layer. output layer. (input layer는 이미 전 data preprocessing 작업 완료). output층에서는 결과값이 나와야하기 때문에 신호값으로 만들어주는 역할을 해야한다. \n",
        "- activation function을 사용하지 않을 때 = linear"
      ],
      "metadata": {
        "id": "ljDW3b7XCtyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation functions\n",
        "\n",
        "* sigmoid function - (0, 1) hidden & output layer 둘 다 사용 가능. 값의 범위가 무조건 0 또는 1로 만들어져야할때 사용. 두 가지일때는 softmax보다 sigmoid 쓰는 것이 좋다. \n",
        "* softmax - 모든 case에 대한 확률을 말해줘야한다. (e.g. 정상30 /위암40 /위염30) 세가지라면 softmax를 쓰는게 좋다. - output layer 확률값으로 바꿔주는 이유? 학습에 있어서 model이 얼마나 틀렸는지 알려주는 것이 중요하다!\n",
        "\n",
        "* Tanh - (-1,1) sigmoid보다 값을 표현할 수 있는 범위가 넓어졌다.(공학적으로) 그러나 필요가 많지는 않다 (layer 1층을 더 쓰는게 편할 때가 많다) 더 다양한 시도등을 쓰기 좋을 때 사용 - e,g, 생성분야. \n",
        "\n",
        "* [Gradient vanishing]: activation function을 써도 layer층이 어느정도 깊어짐에 학습이 안되는 문제 직면 - 왜곡이 심해졌다. 원인이 activation function에 있었다. \n",
        "\n",
        "* Relu function(Rectified Linear Unit)  - layer가 깊어질수록 값에 대한 왜곡 문제 해결. 값의 범위를 줄인다 (음수 0으로 바꿔버림). \n"
      ],
      "metadata": {
        "id": "FxQIHj1yGbNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function\n",
        "\n",
        "* Cross Entropy - 0, 0, 1 - log1은 loss가 0이된다. 1에 가까워질수록 0에 가까워진다. 사실 맞췄는지 여부는 model에게 중요하지 않다. loss값이 중요. (정확도가 100%라고 loss가 0%는 아니다. 역은 통함) 분류일때는 cross entropy\n",
        "\n",
        "* MSE - 수치계산할때는 MSE."
      ],
      "metadata": {
        "id": "H2PwIEvfRIjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch - (hyperparameter) single pass through the entire training datasets전체 데이터 한번 돌면 1번\n",
        "batch - subset of the training data used to update the weights of nn at each iteration within an epoch. update the weights after processing a batch of examples.(# of training examples included in each batch)\n",
        "\n",
        "### Optimizer\n",
        "\n",
        "stochastic gradient descent: (MINI-BATCHES)local minima에 빠지는 것도 방지(빠져나올 수 있는 확률을 만듬) .학습 속도가 빠르다.랜덤하게 batch를 선정해서 데이터를 가져옴.\n",
        "\n",
        "momentum\n",
        "\n",
        "adagrad(adaptive gradient): 방향성 고려. The learning rate is adapted component-wise to the parameters by incorporating knowledge of past observations.\n",
        "\n",
        "adam (momentum + adagrad)"
      ],
      "metadata": {
        "id": "VlQQDS5YUt1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  training with CNN"
      ],
      "metadata": {
        "id": "qH-UfkWFZzkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.Sequential()\n",
        "# input = (28,28)\n",
        "cnn_model.add(tf.keras.layers.Conv2D(32, (3,3),padding = 'same',activation = 'relu',\n",
        "                                     input_shape=(28,28,1)))\n",
        "# hidden output shape= (28,28 ,32)\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2), strides=1, padding='same'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(32,(3,3),padding='same',activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2), strides=1, padding='same'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(1,(3,3),padding='same',activation='relu'))\n",
        "\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2,2), strides=1, padding='same'))\n",
        "\n",
        "# hidden output shape= (28, 28 ,1) => feature , CNN X model = > pixel\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Dropout(0.2)) # model challenging 20 % hide\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Dense(10 , activation ='softmax'))\n",
        "\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cXfsHpw13vk",
        "outputId": "5f0efbde-43dd-45c2-96d9-9bd7b792d4e7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 28, 28, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 28, 28, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 1)         289       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 28, 28, 1)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 111,627\n",
            "Trainable params: 111,627\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nGYjweBzy3RK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_X_train = tf.expand_dims(X_train , axis = -1 )\n",
        "expanded_X_test = tf.expand_dims(X_test, axis=-1)"
      ],
      "metadata": {
        "id": "qQerX-_X0Tck"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 준비 끝!"
      ],
      "metadata": {
        "id": "B21yslU60yVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(expanded_X_train , y_train, epochs=5,\n",
        "\n",
        "              validation_data=(expanded_X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm9aEM2B0ud6",
        "outputId": "0b4cd122-e4cd-415e-c9d3-a31e8a56e8ef"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2449 - accuracy: 0.9229 - val_loss: 0.0981 - val_accuracy: 0.9688\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1124 - accuracy: 0.9656 - val_loss: 0.0740 - val_accuracy: 0.9770\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0867 - accuracy: 0.9731 - val_loss: 0.0555 - val_accuracy: 0.9829\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0760 - accuracy: 0.9755 - val_loss: 0.0606 - val_accuracy: 0.9818\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 0.0577 - val_accuracy: 0.9812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f02a3b820>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}
